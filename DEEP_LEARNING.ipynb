{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "869564d0",
      "metadata": {
        "id": "869564d0"
      },
      "source": [
        "AI \n",
        "- inspired from this definition - A way to make machine mimic human inteligence\n",
        "- effort to automate intellectual tasks performed by humans\n",
        "- is there a way to automate the task humans do\n",
        "- is there a way we can train the machine to do those things\n",
        "- ML- is there a way we can show the machine a lot of info and the expected output and from there let the machine come up with some rules so any times it seesomething similar to the pattern, this will be the output. This leads us to Machine learning.\n",
        "![image-2.png](attachment:image-2.png)\n",
        "- in **Classical Programming** programmers design rules (euristic method / manual) e.g. if age is 44,  income level is 100, we should approve the loan. These are rules we give to the model. The model looks at the rules combined with the data and give an answer.\n",
        "- in **Machine Learning**, we have an understaning of what the answer is, so we give it a data and tell it come up with some rules that match the answers. Our models are rules that match input to output and its called Function in Mathematics\n",
        "- Learning come from the algorithm trying to come of with different parameter values i.e. coefficients associated with each features. e.g X1 for age, X2 for gender, X3 for educational level and Income as our target. fitting the data will produce the  coefficient/ weight of X1, X2 and X3 that will lead to correct prediction of income. If those weights produced are not correct, the mistakes will be large. the model is trying to learn the accurate value of the weight associated with each feature. Hyperparameter tuning is done to adjust those weights the model came up with initially\n",
        "- In Deep Learning, the weights are different but similar concept. Deep Learning has many weight. The weights here are learning rate\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "#### Difference between Machine Learning and Deep Learning\n",
        "![image-3.png](attachment:image-3.png)\n",
        "In ML, we get our data and extract useful features (by cleaning the data, checking correlation, feature selection ) then pass th data to the model e.g. Log Regression to come up with some weight for each of the features that give us the output\n",
        "\n",
        "In deep learning, which performs better, all we do is to clean the data and gve it to aneural network. Let the model look at the data and select the features itself and give the output. It does this multiple times in layers and adjust the coefficient/ weights little by little and pass the result to the next layer to work on it, these process of correctinfg the weight is done multiple times to correctly predict the target. the downside of this process is overfitting because its ddoing the processs multiple time so if the data is small it will overfit\n",
        "\n",
        "- Deep learning is a specific subfield of machine learning\n",
        "- Also called **Representation Leaning**; just like data transformation, when you supply the input dataset to a deep learning model which is a series of layers where in each layer, transformation is occuring. It re-represents or re-transforms the data from the first layer to the last layer in a new way that the machine can understand thereby trying to figure out the patterns in the data. Whatever learning that goes on in the first layer is passed on to the next layer and goes on like that till it gets to the final layer when the model must have understood the pattern to undertake a classificaion\n",
        "- A new take on learning representations from data that puts an emphasis on learning successive layers of increasingly meaningful representations.\n",
        "- These layered representations are learned via models called neural networks, structured in literal layers stacked on top of each other.\n",
        "- structured data work best with shallow models. In fact most of the industries today do not use complex models such as neural networks. However, neural netwroks also has its own benefits and it can be used in Test and image classifcation e.g GAN (Generative Adversarial Network) which is used to generate images similar to an input image\n",
        "![image-4.png](attachment:image-4.png)\n",
        "In deep learning, the outputs is representing number and each layer has its probability. The final layer is going to put everything together. Deep means many layer and many starts from 3. A single layer is called perception\n",
        "![image-5.png](attachment:image-5.png)\n",
        "- each layer is learning different thigs\n",
        "- the first layer learns the basic features of the image\n",
        "- as the layer ncreases, it begins to learn other important advanced features\n",
        "- the use of more than 2 layers is where the name Deep Neural Networks comes to play. A single layer is perception\n",
        "- theconnections in the layers is fully connected network. That is how our brains work. All the neurons in a layer are fully connected to all the neurons in another layer\n",
        "- by the time the learning gets to the last layer, it will put all the results ofprevious layers together and come up with the output in form of probabilities. Probability of the expected output will be the highest\n",
        "\n",
        "#### Features of image and texts datasets\n",
        "unlike a structured dataset with many variables and columns as features, thenumber of pixels together are the features in image dataset. The individual words are the features in texts. That is why images and texts are high dimensional data because there are lots of pixels in images and words respectively\n",
        "\n",
        "#### Artificial Neural Networks (ANNs)\n",
        "ANNs represent a class of machine learning models inspired by studies about the central nervous systems of mammals. They are series of layers that contain interconnected neurons i.e. these neurons relate witone another; the layers pass messages from the neurns in one layer to the other\n",
        "- Each ANN is made up of several interconnected \"neurons\" organized in \"layers.\n",
        "- Neurons in one layer pass messages to neurons in the next layer\n",
        "\n",
        "#### Artificial neuron \n",
        "Artificial neuron is a mathematical function that takes inputs, weighs them separately, sums them up, and passes this sum through a nonlinear function to produce output.\n",
        "- each input has an assiciated weight(coeffiecint) has a product called linear combination. This product is passed through a non-linear function that will transform the input to 0 or 1\n",
        "\n",
        "#### perceptron\n",
        "it's a step function that determines whether a particular neuron is important or can contribute to the target\n",
        "- The perceptron is a simple algorithm that, given an input vector of m features outputs either a 1 (\"yes\") or a 0 (\"no\").\n",
        "- the problem is that it can only capture a linear relationship in the input feature and the output is binary i.e. 0 or 1\n",
        "\n",
        "#### types of perception\n",
        "1. single-layer\n",
        "2. multi-layer: the processing power will increase but it cannot capture a non-linear relationship\n",
        "\n",
        "#### Problems of perceptron\n",
        "- the output is binary i.e. 0 or 1\n",
        "- can only capture a linear relationship in the input feature  \n",
        "- since we cannot take gradient of 0 and 1, we need a function that can trnsform the weighted sum to continuous values rather than 0 and 1 and this leads us to activation function\n",
        "\n",
        "#### Activation function\n",
        "Activation functions are the functions that activate the neurons of any Neural Network. It is similar to the step functin that the perceptron is doing in determining if the input in a neuron is relevant for a model's prediction\n",
        "- These are mathematical functions which are attached to neurons and decide whether or not the current neuron will be activated.\n",
        "- Activation functions do this based on whether the neuron's input is relevant for a model's prediction.\n",
        "- They do so by normalizing the output of any neuron between 1 and 0 or -1 and 1\n",
        "- They also add non-linearity to the neural network.\n",
        "\n",
        "#### Types of Activation function\n",
        "1. Sigmoid / logistic : this is the function working underthe hood for logistic regression; probability value is between 0 and 1\n",
        "2. Tanh: it marks input between -1 and 1\n",
        "3. ReLU: it marks input beween 0and whatever the weighted sum is; if the weighted sum is less that 0, reLU wil give out 0. There are other variants of ReLU such as Leaky ReLU and ELU\n",
        "\n",
        "#### Basic Neural Network\n",
        "![image-6.png](attachment:image-6.png)\n",
        "There is a linear combination between the inputs and the associated weights of each input giving a product and a weighted sum. Activation function to used can be any one above. Research shows that ReLU is one the best due problem it solved called the vanishing gradient.\n",
        "\n",
        "#### What goes on in a neural network layer\n",
        "the transformation implemented in a layer is parameterized by its weights\n",
        "![image-7.png](attachment:image-7.png)\n",
        "- the data receives the input and the associated weights and transforms it; takes the associated weights of the subsequent layer and transforms it to the final layer and makes prediction\n",
        "- it compares the prediction with the true target to find out how the network is doing by calculating the error or loss using the loss function and then give a score\n",
        "- when we get to the score we need to improve. While in machine learning, the process ends here then we begin hyperparameter tuning, for deep learning, the process begins here. There is s need to improve since the initial weights are not perfect so we need a way to adjust the weights. This is where the concept of optimizer comes in\n",
        "\n",
        "#### Optimizers\n",
        "These are the methods used to adjust the weights and learning rate because without adjusting the weights of a neural network, there is no learning. The network want to come up with the appropriate values of the weights associated with each of those features.\n",
        "- it helps to improve accuracy and reduce the overall loss; the more accurate the adjusted weights, the better the results\n",
        "####  Learning rate\n",
        "this is measuring how much you want the weight adjustment to take place; are you adjusting very high or little by little. Humans learn little by little, hence we adjust the weight little by little. \n",
        "- If the learning rate is high then we are jumping (e.g. adjusting downward from 20 to 0), the network will not really learn. If the adjustment is done little by litle\n",
        "- wealso dont wantthe adjustment to be too little\n",
        "- hence, adjustment between 0.01- 0.001 is okay\n",
        "####  Types of Optimizer\n",
        "![image-8.png](attachment:image-8.png)\n",
        "\n",
        "#### Gradient Descent\n",
        "![image-9.png](attachment:image-9.png)\n",
        "Works by iteratively adjusting model parameters (weights) in the direction of the steepest descent of the loss function. It is similar to all optimizers. What makes it different is how it performs the operation\n",
        "- its effectiveness is determined by the types of loss function; this leads us to why we use mean-squared error for evaluation\n",
        "- this is because the cost function C on the y-axis involves the square of the difference between the prediction and the target\n",
        "- The goal of gradient descent is to find the values of the model parameters that minimize the cost function.the goal is to get to where we have the smallest error. When the network gets there\n",
        "#### Gradient Descent\n",
        "1. Batch Gradient Descent: it is computationally intensive because we it processes the entire data before adjusting the weights\n",
        "2. Stochastive Gradient Descent: it randomly selects a subset of data to process\n",
        "3. Mini-Batch Gradient Descent; it processes small amount of data row by row\n",
        "\n",
        "#### Fully connected layer\n",
        "![image-10.png](attachment:image-10.png)\n",
        "all the neuron in one layer is connected to all the neurons in another layer\n",
        "\n",
        "#### fully connected network\n",
        "It consists of a series of fully connected layers that connect every neuron in one layer to every neuron in other layer.\n",
        "- The major advantage of fully connected networks is that they are \"structure agnostic\" i.e. there are no special assumptions needed to be made about the input.\n",
        "- This type of network tends to have weaker performance than special-purpose networks.\n",
        "\n",
        "#### Combat overffiting - Dropout\n",
        "![image-11.png](attachment:image-11.png)\n",
        "it randomly drops neurons that are not contributing to the target to reduce the rate of overfitting\n",
        "- Dropout refers to dropping out the nodes in a neural network.\n",
        "- All the forward and backwards connections with a dropped node are temporarilyremoved, thus creating a new network architecture out of the parent network.\n",
        "- The nodes are dropped by a dropout probability of p.\n",
        "\n",
        "#### create a virtual evironment\n",
        "when you want to run a deep learning network, always create a virtual environmnet before installing any package. Virtaul mean everything you do in that domain is only known in that environment. \n",
        "steps\n",
        "- conda info -e ;used to check if you have any environment before\n",
        "- conda create -n DL_demo python=3.8\n",
        "- y\n",
        "- conda activate DL_demo\n",
        "- conda list\n",
        "- pip install --upgrade pip\n",
        "- cls ; to clear the screen\n",
        "- pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59e431f5",
      "metadata": {
        "id": "59e431f5"
      },
      "source": [
        "## Deep Learning Model Building - Regression Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a180ac8f",
      "metadata": {
        "id": "a180ac8f"
      },
      "source": [
        "#### Import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad704b2c",
      "metadata": {
        "id": "ad704b2c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential # when you want the layers to be added one after the other\n",
        "from tensorflow.keras.layers import Dense # dense is the fully connected network\n",
        "from sklearn.metrics import mean_squared_error # for model evaluation\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eea1912",
      "metadata": {
        "id": "9eea1912"
      },
      "source": [
        "#### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1e4423",
      "metadata": {
        "id": "7b1e4423",
        "outputId": "2305ea20-789a-4eb2-9256-ddd661f4c185"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "      <td>1.059034e+06</td>\n",
              "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "      <td>1.505891e+06</td>\n",
              "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "      <td>1.058988e+06</td>\n",
              "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "      <td>1.260617e+06</td>\n",
              "      <td>USS Barnett\\nFPO AP 44820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "      <td>6.309435e+05</td>\n",
              "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
              "0      79545.458574             5.682861                   7.009188   \n",
              "1      79248.642455             6.002900                   6.730821   \n",
              "2      61287.067179             5.865890                   8.512727   \n",
              "3      63345.240046             7.188236                   5.586729   \n",
              "4      59982.197226             5.040555                   7.839388   \n",
              "\n",
              "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
              "0                          4.09     23086.800503  1.059034e+06   \n",
              "1                          3.09     40173.072174  1.505891e+06   \n",
              "2                          5.13     36882.159400  1.058988e+06   \n",
              "3                          3.26     34310.242831  1.260617e+06   \n",
              "4                          4.23     26354.109472  6.309435e+05   \n",
              "\n",
              "                                             Address  \n",
              "0  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
              "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
              "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
              "3                          USS Barnett\\nFPO AP 44820  \n",
              "4                         USNS Raymond\\nFPO AE 09386  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = r\"C:\\Users\\USER\\Desktop\\USA_Housing.csv\"\n",
        "data = pd.read_csv(path)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10824aba",
      "metadata": {
        "id": "10824aba",
        "outputId": "647b6386-69c7-4a2d-b5df-ae94d7851b74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Avg. Area Income                0\n",
              "Avg. Area House Age             0\n",
              "Avg. Area Number of Rooms       0\n",
              "Avg. Area Number of Bedrooms    0\n",
              "Area Population                 0\n",
              "Price                           0\n",
              "Address                         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7adbb233",
      "metadata": {
        "id": "7adbb233"
      },
      "outputs": [],
      "source": [
        "#### select features and target\n",
        "X = data.drop(['Address', 'Price'], axis = 1)\n",
        "y = data['Price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6c2b38",
      "metadata": {
        "id": "cd6c2b38"
      },
      "outputs": [],
      "source": [
        "#### Split the dataset into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ca8eac",
      "metadata": {
        "id": "a4ca8eac",
        "outputId": "c606d219-b66d-4a96-b586-3bc8111aa9a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4000, 5)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6661bc1e",
      "metadata": {
        "id": "6661bc1e",
        "outputId": "438aab24-1a2d-43c7-d51c-86a5b9abe057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4000,)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7e9e8c2",
      "metadata": {
        "id": "c7e9e8c2"
      },
      "source": [
        "#### Indicate the number of features\n",
        "the first layer takes the input features so we are going to tell the specify how many features we have on our dataset. If this step is incorrect, there will be errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed947a8",
      "metadata": {
        "id": "9ed947a8"
      },
      "outputs": [],
      "source": [
        "# indicate the number of features\n",
        "n_features = X.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dec2270",
      "metadata": {
        "id": "5dec2270"
      },
      "source": [
        "#### Model Architecture\n",
        "designing the network\n",
        "- sequential: it is like designing a bag where we put all the layers and add the layers one after the other\n",
        "- funtional: here we dont add the layers one after the other, we are just passing it. This is the one that mimics the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5a11e5",
      "metadata": {
        "id": "9c5a11e5"
      },
      "outputs": [],
      "source": [
        "# firstly, design the bag \n",
        "Model = Sequential()\n",
        "# the first layer inside the  sequential is always the input layer and that's where we specify no of features\n",
        "# here, we specify the neurons, the units , the activtion  i.e. Relu, weight or kernel initializer i.e. glorot uniform\n",
        "Model.add(Dense(32, input_dim= n_features, activation = \"relu\"))\n",
        "# we the next is the second layer; every layer has its own activation function\n",
        "# the number of neurons is an hyperparameter, it need to be tuned to identify the best\n",
        "# however most times we always start with 32 then 64 then 128\n",
        "Model.add(Dense(64, activation = \"relu\"))\n",
        "# we will be using small neurons in the second hidden layers so it wont be too complex\n",
        "Model.add(Dense(10,activation = \"relu\"))\n",
        "# next is the final layer: because it is a regression problem, the output must be 1\n",
        "# also the final activation will be linear not relu\n",
        "Model.add(Dense(1, activation = \"linear\"))\n",
        "# linear mode: neuron = 1, activtion= linear\n",
        "# classification of 2 categories: neuron =2; activation = sigmoid\n",
        "# classification of more than 2 = softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbd5b8d",
      "metadata": {
        "id": "dfbd5b8d"
      },
      "source": [
        "#### Model Summary\n",
        "to display a summary of the layers and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1554216",
      "metadata": {
        "id": "b1554216",
        "outputId": "518e54d5-3dff-4e72-ea5e-3ee17f01d91b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 32)                192       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,965\n",
            "Trainable params: 2,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044d7cbf",
      "metadata": {
        "id": "044d7cbf"
      },
      "source": [
        "- number of features+ bias/ intercept * neurons\n",
        "- first (5+1) * 32 = 192\n",
        "- second (32+1) * 64 = 2112\n",
        "- third (64+1) * 10 = 650\n",
        "- last layer = (10+1) * 1 = 11\n",
        "- a larger number of parameters may make the model more powerful, but also harder to train and more prone to overfitting.\n",
        "- if it overfits, you can adjust the number of neuron or reduce the number of layers\n",
        "- reducing these will affect the strength of the model; this leads to the use of the standard called dropout; since not all the neurons are important, it randomly removes some of the neurons "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233ee8fd",
      "metadata": {
        "id": "233ee8fd"
      },
      "source": [
        "#### Model compilation\n",
        "to specify the optimizer algorithm to be used during training, the loss function to be used to evaluate the performance of the model, and any additional metrics to be tracked during training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfa0480",
      "metadata": {
        "id": "dcfa0480"
      },
      "outputs": [],
      "source": [
        "Model.compile(loss  = \"mse\", metrics = \"accuracy\", optimizer = \"adam\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3675128c",
      "metadata": {
        "id": "3675128c"
      },
      "source": [
        "#### Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06ebaaad",
      "metadata": {
        "id": "06ebaaad",
        "outputId": "97434081-69d9-45cc-d17d-0e8e326c7646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 - 5s - loss: 1153915158528.0000 - accuracy: 0.0000e+00 - val_loss: 352928038912.0000 - val_accuracy: 0.0000e+00 - 5s/epoch - 50ms/step\n",
            "Epoch 2/5\n",
            "100/100 - 0s - loss: 94627594240.0000 - accuracy: 0.0000e+00 - val_loss: 60482281472.0000 - val_accuracy: 0.0000e+00 - 411ms/epoch - 4ms/step\n",
            "Epoch 3/5\n",
            "100/100 - 0s - loss: 63695314944.0000 - accuracy: 0.0000e+00 - val_loss: 60263067648.0000 - val_accuracy: 0.0000e+00 - 285ms/epoch - 3ms/step\n",
            "Epoch 4/5\n",
            "100/100 - 0s - loss: 63597539328.0000 - accuracy: 0.0000e+00 - val_loss: 60317474816.0000 - val_accuracy: 0.0000e+00 - 274ms/epoch - 3ms/step\n",
            "Epoch 5/5\n",
            "100/100 - 0s - loss: 63508824064.0000 - accuracy: 0.0000e+00 - val_loss: 60181385216.0000 - val_accuracy: 0.0000e+00 - 306ms/epoch - 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1cea09cc190>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Model.fit(x_train, y_train, batch_size = 32, epochs = 5, verbose = 2, validation_split = 0.2)\n",
        "# epoch is the number of iterations\n",
        "# verbose is used to display the iterations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abeec522",
      "metadata": {
        "id": "abeec522"
      },
      "source": [
        "- the loss is very high and the accuracy is at the lowest; "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6380e316",
      "metadata": {
        "id": "6380e316"
      },
      "source": [
        "### rebuild the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6ff67d",
      "metadata": {
        "id": "ad6ff67d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint # to save the best epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da819e0",
      "metadata": {
        "id": "1da819e0"
      },
      "outputs": [],
      "source": [
        "### normalize\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_sd = scaler.fit_transform(x_train)\n",
        "x_test_sd = scaler.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d19f3b",
      "metadata": {
        "id": "e0d19f3b",
        "outputId": "e4f04bd7-6c5a-4ced-a60f-d56b434e9a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_25 (Dense)            (None, 128)               768       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 165,633\n",
            "Trainable params: 165,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model architecture\n",
        "NN_model = Sequential()\n",
        "\n",
        "# The Input Layer :\n",
        "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x_train.shape[1], activation='relu'))\n",
        "\n",
        "# The Hidden Layers :\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(0.2))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
        "NN_model.add(Dropout(0.2))\n",
        "\n",
        "# The Output Layer :\n",
        "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
        "\n",
        "# Compile the network :\n",
        "NN_model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "NN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a992748",
      "metadata": {
        "id": "6a992748"
      },
      "outputs": [],
      "source": [
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5c7e8cb",
      "metadata": {
        "id": "c5c7e8cb",
        "outputId": "8a2e6a9c-32dd-4823-af54-1fe76257ed61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1600749961216.0000 - accuracy: 0.0000e+00\n",
            "Epoch 1: val_loss improved from inf to 1335381983232.00000, saving model to Weights-001--1335381983232.00000.hdf5\n",
            "100/100 [==============================] - 11s 19ms/step - loss: 1598765137920.0000 - accuracy: 0.0000e+00 - val_loss: 1335381983232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 348609675264.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2: val_loss improved from 1335381983232.00000 to 68465586176.00000, saving model to Weights-002--68465586176.00000.hdf5\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 342761930752.0000 - accuracy: 0.0000e+00 - val_loss: 68465586176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 69893963776.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3: val_loss improved from 68465586176.00000 to 62653562880.00000, saving model to Weights-003--62653562880.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 69248647168.0000 - accuracy: 0.0000e+00 - val_loss: 62653562880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 65176776704.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4: val_loss improved from 62653562880.00000 to 58288824320.00000, saving model to Weights-004--58288824320.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 65117376512.0000 - accuracy: 0.0000e+00 - val_loss: 58288824320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 61043167232.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5: val_loss improved from 58288824320.00000 to 53204955136.00000, saving model to Weights-005--53204955136.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 60916367360.0000 - accuracy: 0.0000e+00 - val_loss: 53204955136.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 56880099328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6: val_loss improved from 53204955136.00000 to 49170669568.00000, saving model to Weights-006--49170669568.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 56880099328.0000 - accuracy: 0.0000e+00 - val_loss: 49170669568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 52377579520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7: val_loss improved from 49170669568.00000 to 45485936640.00000, saving model to Weights-007--45485936640.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 52514713600.0000 - accuracy: 0.0000e+00 - val_loss: 45485936640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 49470709760.0000 - accuracy: 0.0000e+00\n",
            "Epoch 8: val_loss improved from 45485936640.00000 to 42327580672.00000, saving model to Weights-008--42327580672.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 49143955456.0000 - accuracy: 0.0000e+00 - val_loss: 42327580672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 44866265088.0000 - accuracy: 0.0000e+00\n",
            "Epoch 9: val_loss improved from 42327580672.00000 to 38194806784.00000, saving model to Weights-009--38194806784.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 45211033600.0000 - accuracy: 0.0000e+00 - val_loss: 38194806784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 41395105792.0000 - accuracy: 0.0000e+00\n",
            "Epoch 10: val_loss improved from 38194806784.00000 to 33857087488.00000, saving model to Weights-010--33857087488.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 41186443264.0000 - accuracy: 0.0000e+00 - val_loss: 33857087488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 38758154240.0000 - accuracy: 0.0000e+00\n",
            "Epoch 11: val_loss improved from 33857087488.00000 to 30149070848.00000, saving model to Weights-011--30149070848.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 38265372672.0000 - accuracy: 0.0000e+00 - val_loss: 30149070848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 34239526912.0000 - accuracy: 0.0000e+00\n",
            "Epoch 12: val_loss improved from 30149070848.00000 to 27848249344.00000, saving model to Weights-012--27848249344.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 34524200960.0000 - accuracy: 0.0000e+00 - val_loss: 27848249344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 30998390784.0000 - accuracy: 0.0000e+00\n",
            "Epoch 13: val_loss improved from 27848249344.00000 to 22881284096.00000, saving model to Weights-013--22881284096.00000.hdf5\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 30943420416.0000 - accuracy: 0.0000e+00 - val_loss: 22881284096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 26637314048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 14: val_loss improved from 22881284096.00000 to 19391242240.00000, saving model to Weights-014--19391242240.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 26637314048.0000 - accuracy: 0.0000e+00 - val_loss: 19391242240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 23728857088.0000 - accuracy: 0.0000e+00\n",
            "Epoch 15: val_loss improved from 19391242240.00000 to 16397598720.00000, saving model to Weights-015--16397598720.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 23813021696.0000 - accuracy: 0.0000e+00 - val_loss: 16397598720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 20904509440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 16: val_loss improved from 16397598720.00000 to 14246231040.00000, saving model to Weights-016--14246231040.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 20897460224.0000 - accuracy: 0.0000e+00 - val_loss: 14246231040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 19594147840.0000 - accuracy: 0.0000e+00\n",
            "Epoch 17: val_loss improved from 14246231040.00000 to 12429978624.00000, saving model to Weights-017--12429978624.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 19366103040.0000 - accuracy: 0.0000e+00 - val_loss: 12429978624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 18255460352.0000 - accuracy: 0.0000e+00\n",
            "Epoch 18: val_loss improved from 12429978624.00000 to 11337783296.00000, saving model to Weights-018--11337783296.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 18163802112.0000 - accuracy: 0.0000e+00 - val_loss: 11337783296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 16519044096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 19: val_loss improved from 11337783296.00000 to 11035210752.00000, saving model to Weights-019--11035210752.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16439342080.0000 - accuracy: 0.0000e+00 - val_loss: 11035210752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 15905246208.0000 - accuracy: 0.0000e+00\n",
            "Epoch 20: val_loss did not improve from 11035210752.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16188314624.0000 - accuracy: 0.0000e+00 - val_loss: 11683805184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16728549376.0000 - accuracy: 0.0000e+00\n",
            "Epoch 21: val_loss improved from 11035210752.00000 to 10623632384.00000, saving model to Weights-021--10623632384.00000.hdf5\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16728549376.0000 - accuracy: 0.0000e+00 - val_loss: 10623632384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 16397813760.0000 - accuracy: 0.0000e+00\n",
            "Epoch 22: val_loss did not improve from 10623632384.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16174501888.0000 - accuracy: 0.0000e+00 - val_loss: 10687738880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16435309568.0000 - accuracy: 0.0000e+00\n",
            "Epoch 23: val_loss did not improve from 10623632384.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16429912064.0000 - accuracy: 0.0000e+00 - val_loss: 11014360064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16504166400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 24: val_loss did not improve from 10623632384.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16504166400.0000 - accuracy: 0.0000e+00 - val_loss: 10846682112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16203999232.0000 - accuracy: 0.0000e+00\n",
            "Epoch 25: val_loss did not improve from 10623632384.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16203999232.0000 - accuracy: 0.0000e+00 - val_loss: 10760633344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 15606465536.0000 - accuracy: 0.0000e+00\n",
            "Epoch 26: val_loss did not improve from 10623632384.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 15585326080.0000 - accuracy: 0.0000e+00 - val_loss: 11574253568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16151849984.0000 - accuracy: 0.0000e+00\n",
            "Epoch 27: val_loss improved from 10623632384.00000 to 10554142720.00000, saving model to Weights-027--10554142720.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16158831616.0000 - accuracy: 0.0000e+00 - val_loss: 10554142720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 16351476736.0000 - accuracy: 0.0000e+00\n",
            "Epoch 28: val_loss did not improve from 10554142720.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16403155968.0000 - accuracy: 0.0000e+00 - val_loss: 10978323456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 16431328256.0000 - accuracy: 0.0000e+00\n",
            "Epoch 29: val_loss did not improve from 10554142720.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16270729216.0000 - accuracy: 0.0000e+00 - val_loss: 10637135872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16091798528.0000 - accuracy: 0.0000e+00\n",
            "Epoch 30: val_loss improved from 10554142720.00000 to 10525684736.00000, saving model to Weights-030--10525684736.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16056203264.0000 - accuracy: 0.0000e+00 - val_loss: 10525684736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16055771136.0000 - accuracy: 0.0000e+00\n",
            "Epoch 31: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16052183040.0000 - accuracy: 0.0000e+00 - val_loss: 10564271104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16416029696.0000 - accuracy: 0.0000e+00\n",
            "Epoch 32: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16404221952.0000 - accuracy: 0.0000e+00 - val_loss: 10542531584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 15862245376.0000 - accuracy: 0.0000e+00\n",
            "Epoch 33: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 15900039168.0000 - accuracy: 0.0000e+00 - val_loss: 10774540288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 16437442560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 34: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16280999936.0000 - accuracy: 0.0000e+00 - val_loss: 11253553152.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16621333504.0000 - accuracy: 0.0000e+00\n",
            "Epoch 35: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16621333504.0000 - accuracy: 0.0000e+00 - val_loss: 10529000448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 16169907200.0000 - accuracy: 0.0000e+00\n",
            "Epoch 36: val_loss did not improve from 10525684736.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16194657280.0000 - accuracy: 0.0000e+00 - val_loss: 10693046272.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 16266178560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 37: val_loss improved from 10525684736.00000 to 10521490432.00000, saving model to Weights-037--10521490432.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16115302400.0000 - accuracy: 0.0000e+00 - val_loss: 10521490432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 16110340096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 38: val_loss did not improve from 10521490432.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16039727104.0000 - accuracy: 0.0000e+00 - val_loss: 10531557376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16028181504.0000 - accuracy: 0.0000e+00\n",
            "Epoch 39: val_loss did not improve from 10521490432.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15931929600.0000 - accuracy: 0.0000e+00 - val_loss: 11601674240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 16390085632.0000 - accuracy: 0.0000e+00\n",
            "Epoch 40: val_loss did not improve from 10521490432.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16360785920.0000 - accuracy: 0.0000e+00 - val_loss: 10743100416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 15921778688.0000 - accuracy: 0.0000e+00\n",
            "Epoch 41: val_loss improved from 10521490432.00000 to 10503476224.00000, saving model to Weights-041--10503476224.00000.hdf5\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15985897472.0000 - accuracy: 0.0000e+00 - val_loss: 10503476224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 15976157184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 42: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16000957440.0000 - accuracy: 0.0000e+00 - val_loss: 11037625344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16029928448.0000 - accuracy: 0.0000e+00\n",
            "Epoch 43: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16024541184.0000 - accuracy: 0.0000e+00 - val_loss: 10841171968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16253334528.0000 - accuracy: 0.0000e+00\n",
            "Epoch 44: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16428847104.0000 - accuracy: 0.0000e+00 - val_loss: 11018132480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16586024960.0000 - accuracy: 0.0000e+00\n",
            "Epoch 45: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16492023808.0000 - accuracy: 0.0000e+00 - val_loss: 10555365376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 15996100608.0000 - accuracy: 0.0000e+00\n",
            "Epoch 46: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16046410752.0000 - accuracy: 0.0000e+00 - val_loss: 10610315264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16806251520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 47: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16732729344.0000 - accuracy: 0.0000e+00 - val_loss: 10610103296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16710401024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 48: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16716355584.0000 - accuracy: 0.0000e+00 - val_loss: 10520735744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 16133157888.0000 - accuracy: 0.0000e+00\n",
            "Epoch 49: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16176560128.0000 - accuracy: 0.0000e+00 - val_loss: 10856988672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 17359425536.0000 - accuracy: 0.0000e+00\n",
            "Epoch 50: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 17212059648.0000 - accuracy: 0.0000e+00 - val_loss: 10771881984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16041981952.0000 - accuracy: 0.0000e+00\n",
            "Epoch 51: val_loss did not improve from 10503476224.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16041981952.0000 - accuracy: 0.0000e+00 - val_loss: 10520261632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 16126050304.0000 - accuracy: 0.0000e+00\n",
            "Epoch 52: val_loss improved from 10503476224.00000 to 10468213760.00000, saving model to Weights-052--10468213760.00000.hdf5\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16359447552.0000 - accuracy: 0.0000e+00 - val_loss: 10468213760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16007030784.0000 - accuracy: 0.0000e+00\n",
            "Epoch 53: val_loss did not improve from 10468213760.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16007030784.0000 - accuracy: 0.0000e+00 - val_loss: 11249142784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 15626969088.0000 - accuracy: 0.0000e+00\n",
            "Epoch 54: val_loss did not improve from 10468213760.00000\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 15717108736.0000 - accuracy: 0.0000e+00 - val_loss: 10532242432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 16448477184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 55: val_loss did not improve from 10468213760.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16510961664.0000 - accuracy: 0.0000e+00 - val_loss: 10490635264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16454324224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 56: val_loss did not improve from 10468213760.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16391723008.0000 - accuracy: 0.0000e+00 - val_loss: 11266790400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 16191574016.0000 - accuracy: 0.0000e+00\n",
            "Epoch 57: val_loss did not improve from 10468213760.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16070780928.0000 - accuracy: 0.0000e+00 - val_loss: 10500442112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16134523904.0000 - accuracy: 0.0000e+00\n",
            "Epoch 58: val_loss improved from 10468213760.00000 to 10459440128.00000, saving model to Weights-058--10459440128.00000.hdf5\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 16129229824.0000 - accuracy: 0.0000e+00 - val_loss: 10459440128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 15968811008.0000 - accuracy: 0.0000e+00\n",
            "Epoch 59: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16000753664.0000 - accuracy: 0.0000e+00 - val_loss: 10566248448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 16371430400.0000 - accuracy: 0.0000e+00\n",
            "Epoch 60: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16351199232.0000 - accuracy: 0.0000e+00 - val_loss: 11014115328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16103044096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 61: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16103044096.0000 - accuracy: 0.0000e+00 - val_loss: 11247074304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 15395654656.0000 - accuracy: 0.0000e+00\n",
            "Epoch 62: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15398544384.0000 - accuracy: 0.0000e+00 - val_loss: 10653504512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16469842944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 63: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16518586368.0000 - accuracy: 0.0000e+00 - val_loss: 10577522688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 15853787136.0000 - accuracy: 0.0000e+00\n",
            "Epoch 64: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15846323200.0000 - accuracy: 0.0000e+00 - val_loss: 10504298496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16258695168.0000 - accuracy: 0.0000e+00\n",
            "Epoch 65: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16310211584.0000 - accuracy: 0.0000e+00 - val_loss: 11059598336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16613358592.0000 - accuracy: 0.0000e+00\n",
            "Epoch 66: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16613358592.0000 - accuracy: 0.0000e+00 - val_loss: 10545146880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16170355712.0000 - accuracy: 0.0000e+00\n",
            "Epoch 67: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 16391589888.0000 - accuracy: 0.0000e+00 - val_loss: 10494030848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 15766326272.0000 - accuracy: 0.0000e+00\n",
            "Epoch 68: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 15775600640.0000 - accuracy: 0.0000e+00 - val_loss: 10582000640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 16447628288.0000 - accuracy: 0.0000e+00\n",
            "Epoch 69: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16500148224.0000 - accuracy: 0.0000e+00 - val_loss: 10530460672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16164761600.0000 - accuracy: 0.0000e+00\n",
            "Epoch 70: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16138329088.0000 - accuracy: 0.0000e+00 - val_loss: 10530376704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16613423104.0000 - accuracy: 0.0000e+00\n",
            "Epoch 71: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16613423104.0000 - accuracy: 0.0000e+00 - val_loss: 10980491264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 16615626752.0000 - accuracy: 0.0000e+00\n",
            "Epoch 72: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16651481088.0000 - accuracy: 0.0000e+00 - val_loss: 10643299328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 16114561024.0000 - accuracy: 0.0000e+00\n",
            "Epoch 73: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16079892480.0000 - accuracy: 0.0000e+00 - val_loss: 11431803904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16585160704.0000 - accuracy: 0.0000e+00\n",
            "Epoch 74: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16561514496.0000 - accuracy: 0.0000e+00 - val_loss: 10817485824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16358708224.0000 - accuracy: 0.0000e+00\n",
            "Epoch 75: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16340852736.0000 - accuracy: 0.0000e+00 - val_loss: 10705215488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 16475696128.0000 - accuracy: 0.0000e+00\n",
            "Epoch 76: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16402124800.0000 - accuracy: 0.0000e+00 - val_loss: 10641610752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 16033224704.0000 - accuracy: 0.0000e+00\n",
            "Epoch 77: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16033224704.0000 - accuracy: 0.0000e+00 - val_loss: 11576321024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 16230532096.0000 - accuracy: 0.0000e+00\n",
            "Epoch 78: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16197438464.0000 - accuracy: 0.0000e+00 - val_loss: 10561696768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16337873920.0000 - accuracy: 0.0000e+00\n",
            "Epoch 79: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16330190848.0000 - accuracy: 0.0000e+00 - val_loss: 10614089728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 16143926272.0000 - accuracy: 0.0000e+00\n",
            "Epoch 80: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16154018816.0000 - accuracy: 0.0000e+00 - val_loss: 10555272192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - ETA: 0s - loss: 15990566912.0000 - accuracy: 0.0000e+00\n",
            "Epoch 81: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15990566912.0000 - accuracy: 0.0000e+00 - val_loss: 10508200960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 15851919360.0000 - accuracy: 0.0000e+00\n",
            "Epoch 82: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15678065664.0000 - accuracy: 0.0000e+00 - val_loss: 12211155968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 16253010944.0000 - accuracy: 0.0000e+00\n",
            "Epoch 83: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16228381696.0000 - accuracy: 0.0000e+00 - val_loss: 10510901248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16378440704.0000 - accuracy: 0.0000e+00\n",
            "Epoch 84: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16318267392.0000 - accuracy: 0.0000e+00 - val_loss: 10536057856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 15902651392.0000 - accuracy: 0.0000e+00\n",
            "Epoch 85: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 15897731072.0000 - accuracy: 0.0000e+00 - val_loss: 10523164672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 15785930752.0000 - accuracy: 0.0000e+00\n",
            "Epoch 86: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15789145088.0000 - accuracy: 0.0000e+00 - val_loss: 10506670080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 15385149440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 87: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15369803776.0000 - accuracy: 0.0000e+00 - val_loss: 10791209984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 16265195520.0000 - accuracy: 0.0000e+00\n",
            "Epoch 88: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16226030592.0000 - accuracy: 0.0000e+00 - val_loss: 11126735872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 15750621184.0000 - accuracy: 0.0000e+00\n",
            "Epoch 89: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 15813699584.0000 - accuracy: 0.0000e+00 - val_loss: 10765026304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 16477885440.0000 - accuracy: 0.0000e+00\n",
            "Epoch 90: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16494405632.0000 - accuracy: 0.0000e+00 - val_loss: 10506358784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 16439651328.0000 - accuracy: 0.0000e+00\n",
            "Epoch 91: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16515099648.0000 - accuracy: 0.0000e+00 - val_loss: 10639721472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 15733058560.0000 - accuracy: 0.0000e+00\n",
            "Epoch 92: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 15609140224.0000 - accuracy: 0.0000e+00 - val_loss: 10735551488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 15600770048.0000 - accuracy: 0.0000e+00\n",
            "Epoch 93: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15745139712.0000 - accuracy: 0.0000e+00 - val_loss: 10964073472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 16224602112.0000 - accuracy: 0.0000e+00\n",
            "Epoch 94: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 16280550400.0000 - accuracy: 0.0000e+00 - val_loss: 10530123776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16034609152.0000 - accuracy: 0.0000e+00\n",
            "Epoch 95: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16090860544.0000 - accuracy: 0.0000e+00 - val_loss: 10470176768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 15819607040.0000 - accuracy: 0.0000e+00\n",
            "Epoch 96: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 15812316160.0000 - accuracy: 0.0000e+00 - val_loss: 10625027072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 16201376768.0000 - accuracy: 0.0000e+00\n",
            "Epoch 97: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 16216166400.0000 - accuracy: 0.0000e+00 - val_loss: 10498143232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 16474316800.0000 - accuracy: 0.0000e+00\n",
            "Epoch 98: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 16430839808.0000 - accuracy: 0.0000e+00 - val_loss: 11158284288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 16225799168.0000 - accuracy: 0.0000e+00\n",
            "Epoch 99: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 16171527168.0000 - accuracy: 0.0000e+00 - val_loss: 10790234112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 16240926720.0000 - accuracy: 0.0000e+00\n",
            "Epoch 100: val_loss did not improve from 10459440128.00000\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 16249972736.0000 - accuracy: 0.0000e+00 - val_loss: 12236419072.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1cea2126370>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NN_model.fit(x_train_sd, y_train, epochs=100, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b3ff1e",
      "metadata": {
        "id": "75b3ff1e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import kernel_metrics\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape = (n_features,), activation = \"relu\"))\n",
        "# model.add(Dense(64, activation = \"relu\"))\n",
        "# model.add(Dense(10, activation = \"relu\"))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b12e27cf",
      "metadata": {
        "id": "b12e27cf",
        "outputId": "85c73a13-378f-4efe-930b-78ecec64e9b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 32)                192       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225\n",
            "Trainable params: 225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64932d75",
      "metadata": {
        "id": "64932d75"
      },
      "outputs": [],
      "source": [
        "# compile the network\n",
        "#opt = Adam(0.01)\n",
        "model.compile(optimizer='rmsprop', loss = \"mse\", metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b478872e",
      "metadata": {
        "id": "b478872e",
        "outputId": "ee77c2a2-5d9d-4cdf-e248-68040c83ac7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 1s - loss: 16324293632.0000 - accuracy: 0.0000e+00 - val_loss: 10535309312.0000 - val_accuracy: 0.0000e+00 - 648ms/epoch - 6ms/step\n",
            "Epoch 2/100\n",
            "100/100 - 1s - loss: 15727070208.0000 - accuracy: 0.0000e+00 - val_loss: 10656602112.0000 - val_accuracy: 0.0000e+00 - 608ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "100/100 - 0s - loss: 16255862784.0000 - accuracy: 0.0000e+00 - val_loss: 10481474560.0000 - val_accuracy: 0.0000e+00 - 500ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "100/100 - 1s - loss: 16319731712.0000 - accuracy: 0.0000e+00 - val_loss: 10781883392.0000 - val_accuracy: 0.0000e+00 - 602ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "100/100 - 1s - loss: 15952739328.0000 - accuracy: 0.0000e+00 - val_loss: 10825900032.0000 - val_accuracy: 0.0000e+00 - 647ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "100/100 - 1s - loss: 16626576384.0000 - accuracy: 0.0000e+00 - val_loss: 10595051520.0000 - val_accuracy: 0.0000e+00 - 723ms/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "100/100 - 1s - loss: 16350972928.0000 - accuracy: 0.0000e+00 - val_loss: 10602489856.0000 - val_accuracy: 0.0000e+00 - 629ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "100/100 - 1s - loss: 16423648256.0000 - accuracy: 0.0000e+00 - val_loss: 11201282048.0000 - val_accuracy: 0.0000e+00 - 601ms/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "100/100 - 1s - loss: 15956724736.0000 - accuracy: 0.0000e+00 - val_loss: 11691126784.0000 - val_accuracy: 0.0000e+00 - 525ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "100/100 - 1s - loss: 16667484160.0000 - accuracy: 0.0000e+00 - val_loss: 11055607808.0000 - val_accuracy: 0.0000e+00 - 620ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "100/100 - 1s - loss: 15757303808.0000 - accuracy: 0.0000e+00 - val_loss: 10551888896.0000 - val_accuracy: 0.0000e+00 - 567ms/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "100/100 - 1s - loss: 16336654336.0000 - accuracy: 0.0000e+00 - val_loss: 10595816448.0000 - val_accuracy: 0.0000e+00 - 614ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "100/100 - 0s - loss: 15626498048.0000 - accuracy: 0.0000e+00 - val_loss: 10542997504.0000 - val_accuracy: 0.0000e+00 - 500ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "100/100 - 1s - loss: 16367318016.0000 - accuracy: 0.0000e+00 - val_loss: 10492967936.0000 - val_accuracy: 0.0000e+00 - 537ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "100/100 - 0s - loss: 16865689600.0000 - accuracy: 0.0000e+00 - val_loss: 10483290112.0000 - val_accuracy: 0.0000e+00 - 492ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "100/100 - 1s - loss: 15314236416.0000 - accuracy: 0.0000e+00 - val_loss: 10576776192.0000 - val_accuracy: 0.0000e+00 - 591ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "100/100 - 0s - loss: 16504708096.0000 - accuracy: 0.0000e+00 - val_loss: 10502689792.0000 - val_accuracy: 0.0000e+00 - 480ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "100/100 - 1s - loss: 15932756992.0000 - accuracy: 0.0000e+00 - val_loss: 11717730304.0000 - val_accuracy: 0.0000e+00 - 623ms/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "100/100 - 0s - loss: 16030489600.0000 - accuracy: 0.0000e+00 - val_loss: 10729977856.0000 - val_accuracy: 0.0000e+00 - 481ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "100/100 - 1s - loss: 16006738944.0000 - accuracy: 0.0000e+00 - val_loss: 10518900736.0000 - val_accuracy: 0.0000e+00 - 604ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "100/100 - 1s - loss: 16256129024.0000 - accuracy: 0.0000e+00 - val_loss: 10541007872.0000 - val_accuracy: 0.0000e+00 - 545ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "100/100 - 1s - loss: 16326341632.0000 - accuracy: 0.0000e+00 - val_loss: 10493276160.0000 - val_accuracy: 0.0000e+00 - 627ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "100/100 - 1s - loss: 16018247680.0000 - accuracy: 0.0000e+00 - val_loss: 10491479040.0000 - val_accuracy: 0.0000e+00 - 525ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "100/100 - 1s - loss: 16563129344.0000 - accuracy: 0.0000e+00 - val_loss: 10914436096.0000 - val_accuracy: 0.0000e+00 - 634ms/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "100/100 - 1s - loss: 16490844160.0000 - accuracy: 0.0000e+00 - val_loss: 10488654848.0000 - val_accuracy: 0.0000e+00 - 509ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "100/100 - 1s - loss: 15975786496.0000 - accuracy: 0.0000e+00 - val_loss: 11427129344.0000 - val_accuracy: 0.0000e+00 - 590ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "100/100 - 1s - loss: 16521703424.0000 - accuracy: 0.0000e+00 - val_loss: 13074131968.0000 - val_accuracy: 0.0000e+00 - 570ms/epoch - 6ms/step\n",
            "Epoch 28/100\n",
            "100/100 - 1s - loss: 16963668992.0000 - accuracy: 0.0000e+00 - val_loss: 10586375168.0000 - val_accuracy: 0.0000e+00 - 607ms/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "100/100 - 1s - loss: 16476420096.0000 - accuracy: 0.0000e+00 - val_loss: 10825537536.0000 - val_accuracy: 0.0000e+00 - 518ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "100/100 - 1s - loss: 15636946944.0000 - accuracy: 0.0000e+00 - val_loss: 10532651008.0000 - val_accuracy: 0.0000e+00 - 539ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "100/100 - 1s - loss: 15790761984.0000 - accuracy: 0.0000e+00 - val_loss: 10585675776.0000 - val_accuracy: 0.0000e+00 - 561ms/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "100/100 - 1s - loss: 15339453440.0000 - accuracy: 0.0000e+00 - val_loss: 10621780992.0000 - val_accuracy: 0.0000e+00 - 662ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "100/100 - 1s - loss: 15884760064.0000 - accuracy: 0.0000e+00 - val_loss: 10529403904.0000 - val_accuracy: 0.0000e+00 - 651ms/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "100/100 - 1s - loss: 15898897408.0000 - accuracy: 0.0000e+00 - val_loss: 11996697600.0000 - val_accuracy: 0.0000e+00 - 680ms/epoch - 7ms/step\n",
            "Epoch 35/100\n",
            "100/100 - 1s - loss: 16351556608.0000 - accuracy: 0.0000e+00 - val_loss: 10691708928.0000 - val_accuracy: 0.0000e+00 - 592ms/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "100/100 - 1s - loss: 17429379072.0000 - accuracy: 0.0000e+00 - val_loss: 10959817728.0000 - val_accuracy: 0.0000e+00 - 583ms/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "100/100 - 1s - loss: 16230688768.0000 - accuracy: 0.0000e+00 - val_loss: 10973427712.0000 - val_accuracy: 0.0000e+00 - 604ms/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "100/100 - 1s - loss: 16458316800.0000 - accuracy: 0.0000e+00 - val_loss: 10474055680.0000 - val_accuracy: 0.0000e+00 - 542ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "100/100 - 1s - loss: 16456329216.0000 - accuracy: 0.0000e+00 - val_loss: 11955162112.0000 - val_accuracy: 0.0000e+00 - 560ms/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "100/100 - 0s - loss: 15742876672.0000 - accuracy: 0.0000e+00 - val_loss: 10489693184.0000 - val_accuracy: 0.0000e+00 - 476ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "100/100 - 1s - loss: 16505671680.0000 - accuracy: 0.0000e+00 - val_loss: 10477692928.0000 - val_accuracy: 0.0000e+00 - 540ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "100/100 - 1s - loss: 16004447232.0000 - accuracy: 0.0000e+00 - val_loss: 10524340224.0000 - val_accuracy: 0.0000e+00 - 517ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "100/100 - 1s - loss: 16449161216.0000 - accuracy: 0.0000e+00 - val_loss: 11006266368.0000 - val_accuracy: 0.0000e+00 - 575ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "100/100 - 0s - loss: 16546821120.0000 - accuracy: 0.0000e+00 - val_loss: 10690356224.0000 - val_accuracy: 0.0000e+00 - 492ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "100/100 - 1s - loss: 16321323008.0000 - accuracy: 0.0000e+00 - val_loss: 10653704192.0000 - val_accuracy: 0.0000e+00 - 538ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "100/100 - 0s - loss: 16280274944.0000 - accuracy: 0.0000e+00 - val_loss: 10633111552.0000 - val_accuracy: 0.0000e+00 - 498ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "100/100 - 1s - loss: 16108051456.0000 - accuracy: 0.0000e+00 - val_loss: 10757788672.0000 - val_accuracy: 0.0000e+00 - 507ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "100/100 - 1s - loss: 16051340288.0000 - accuracy: 0.0000e+00 - val_loss: 12014238720.0000 - val_accuracy: 0.0000e+00 - 528ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "100/100 - 0s - loss: 15612430336.0000 - accuracy: 0.0000e+00 - val_loss: 11032614912.0000 - val_accuracy: 0.0000e+00 - 484ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "100/100 - 1s - loss: 15985226752.0000 - accuracy: 0.0000e+00 - val_loss: 10761517056.0000 - val_accuracy: 0.0000e+00 - 531ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "100/100 - 0s - loss: 16270123008.0000 - accuracy: 0.0000e+00 - val_loss: 11026395136.0000 - val_accuracy: 0.0000e+00 - 478ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "100/100 - 1s - loss: 16079294464.0000 - accuracy: 0.0000e+00 - val_loss: 10498242560.0000 - val_accuracy: 0.0000e+00 - 544ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "100/100 - 0s - loss: 16024918016.0000 - accuracy: 0.0000e+00 - val_loss: 10653649920.0000 - val_accuracy: 0.0000e+00 - 475ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "100/100 - 1s - loss: 16049472512.0000 - accuracy: 0.0000e+00 - val_loss: 10543312896.0000 - val_accuracy: 0.0000e+00 - 531ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "100/100 - 0s - loss: 16473188352.0000 - accuracy: 0.0000e+00 - val_loss: 10820374528.0000 - val_accuracy: 0.0000e+00 - 494ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "100/100 - 1s - loss: 16190561280.0000 - accuracy: 0.0000e+00 - val_loss: 10598864896.0000 - val_accuracy: 0.0000e+00 - 576ms/epoch - 6ms/step\n",
            "Epoch 57/100\n",
            "100/100 - 1s - loss: 16371874816.0000 - accuracy: 0.0000e+00 - val_loss: 11399280640.0000 - val_accuracy: 0.0000e+00 - 508ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "100/100 - 1s - loss: 15946300416.0000 - accuracy: 0.0000e+00 - val_loss: 10624625664.0000 - val_accuracy: 0.0000e+00 - 560ms/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "100/100 - 1s - loss: 16015923200.0000 - accuracy: 0.0000e+00 - val_loss: 10640142336.0000 - val_accuracy: 0.0000e+00 - 504ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "100/100 - 1s - loss: 16476350464.0000 - accuracy: 0.0000e+00 - val_loss: 11063217152.0000 - val_accuracy: 0.0000e+00 - 547ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "100/100 - 0s - loss: 16164818944.0000 - accuracy: 0.0000e+00 - val_loss: 11103220736.0000 - val_accuracy: 0.0000e+00 - 487ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "100/100 - 1s - loss: 16061042688.0000 - accuracy: 0.0000e+00 - val_loss: 11100901376.0000 - val_accuracy: 0.0000e+00 - 548ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "100/100 - 1s - loss: 15800709120.0000 - accuracy: 0.0000e+00 - val_loss: 10627030016.0000 - val_accuracy: 0.0000e+00 - 522ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "100/100 - 0s - loss: 16854835200.0000 - accuracy: 0.0000e+00 - val_loss: 10557268992.0000 - val_accuracy: 0.0000e+00 - 488ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "100/100 - 1s - loss: 16545626112.0000 - accuracy: 0.0000e+00 - val_loss: 10491867136.0000 - val_accuracy: 0.0000e+00 - 539ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "100/100 - 0s - loss: 15927242752.0000 - accuracy: 0.0000e+00 - val_loss: 10495576064.0000 - val_accuracy: 0.0000e+00 - 487ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "100/100 - 1s - loss: 16076908544.0000 - accuracy: 0.0000e+00 - val_loss: 10766811136.0000 - val_accuracy: 0.0000e+00 - 585ms/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "100/100 - 1s - loss: 15648614400.0000 - accuracy: 0.0000e+00 - val_loss: 10784534528.0000 - val_accuracy: 0.0000e+00 - 609ms/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "100/100 - 1s - loss: 16161646592.0000 - accuracy: 0.0000e+00 - val_loss: 10497330176.0000 - val_accuracy: 0.0000e+00 - 684ms/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "100/100 - 1s - loss: 15869433856.0000 - accuracy: 0.0000e+00 - val_loss: 12491957248.0000 - val_accuracy: 0.0000e+00 - 613ms/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "100/100 - 1s - loss: 16817603584.0000 - accuracy: 0.0000e+00 - val_loss: 10928285696.0000 - val_accuracy: 0.0000e+00 - 587ms/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "100/100 - 1s - loss: 16411642880.0000 - accuracy: 0.0000e+00 - val_loss: 10512322560.0000 - val_accuracy: 0.0000e+00 - 610ms/epoch - 6ms/step\n",
            "Epoch 73/100\n",
            "100/100 - 1s - loss: 15820892160.0000 - accuracy: 0.0000e+00 - val_loss: 10499552256.0000 - val_accuracy: 0.0000e+00 - 547ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "100/100 - 1s - loss: 15778432000.0000 - accuracy: 0.0000e+00 - val_loss: 10708344832.0000 - val_accuracy: 0.0000e+00 - 602ms/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "100/100 - 1s - loss: 16488389632.0000 - accuracy: 0.0000e+00 - val_loss: 10574119936.0000 - val_accuracy: 0.0000e+00 - 548ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "100/100 - 1s - loss: 15632197632.0000 - accuracy: 0.0000e+00 - val_loss: 11408482304.0000 - val_accuracy: 0.0000e+00 - 600ms/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "100/100 - 1s - loss: 16663395328.0000 - accuracy: 0.0000e+00 - val_loss: 12025186304.0000 - val_accuracy: 0.0000e+00 - 523ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "100/100 - 1s - loss: 15987357696.0000 - accuracy: 0.0000e+00 - val_loss: 10598282240.0000 - val_accuracy: 0.0000e+00 - 565ms/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "100/100 - 1s - loss: 16150420480.0000 - accuracy: 0.0000e+00 - val_loss: 10500059136.0000 - val_accuracy: 0.0000e+00 - 504ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "100/100 - 1s - loss: 16011582464.0000 - accuracy: 0.0000e+00 - val_loss: 10671722496.0000 - val_accuracy: 0.0000e+00 - 541ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "100/100 - 0s - loss: 15961991168.0000 - accuracy: 0.0000e+00 - val_loss: 10593478656.0000 - val_accuracy: 0.0000e+00 - 475ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "100/100 - 0s - loss: 15967541248.0000 - accuracy: 0.0000e+00 - val_loss: 10539741184.0000 - val_accuracy: 0.0000e+00 - 479ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "100/100 - 1s - loss: 16116566016.0000 - accuracy: 0.0000e+00 - val_loss: 10939817984.0000 - val_accuracy: 0.0000e+00 - 536ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "100/100 - 1s - loss: 15577655296.0000 - accuracy: 0.0000e+00 - val_loss: 10529766400.0000 - val_accuracy: 0.0000e+00 - 503ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "100/100 - 1s - loss: 15804651520.0000 - accuracy: 0.0000e+00 - val_loss: 10686754816.0000 - val_accuracy: 0.0000e+00 - 553ms/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "100/100 - 0s - loss: 16418641920.0000 - accuracy: 0.0000e+00 - val_loss: 10932303872.0000 - val_accuracy: 0.0000e+00 - 478ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "100/100 - 1s - loss: 15916119040.0000 - accuracy: 0.0000e+00 - val_loss: 10769695744.0000 - val_accuracy: 0.0000e+00 - 543ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "100/100 - 0s - loss: 16104633344.0000 - accuracy: 0.0000e+00 - val_loss: 10765976576.0000 - val_accuracy: 0.0000e+00 - 479ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "100/100 - 1s - loss: 16171551744.0000 - accuracy: 0.0000e+00 - val_loss: 10504498176.0000 - val_accuracy: 0.0000e+00 - 537ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "100/100 - 0s - loss: 16056998912.0000 - accuracy: 0.0000e+00 - val_loss: 10527666176.0000 - val_accuracy: 0.0000e+00 - 499ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "100/100 - 1s - loss: 15821019136.0000 - accuracy: 0.0000e+00 - val_loss: 10652718080.0000 - val_accuracy: 0.0000e+00 - 548ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "100/100 - 1s - loss: 16534288384.0000 - accuracy: 0.0000e+00 - val_loss: 11382096896.0000 - val_accuracy: 0.0000e+00 - 530ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "100/100 - 1s - loss: 16167282688.0000 - accuracy: 0.0000e+00 - val_loss: 10829946880.0000 - val_accuracy: 0.0000e+00 - 528ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "100/100 - 1s - loss: 15700554752.0000 - accuracy: 0.0000e+00 - val_loss: 10535792640.0000 - val_accuracy: 0.0000e+00 - 519ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "100/100 - 1s - loss: 15567931392.0000 - accuracy: 0.0000e+00 - val_loss: 10793513984.0000 - val_accuracy: 0.0000e+00 - 525ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "100/100 - 1s - loss: 15736287232.0000 - accuracy: 0.0000e+00 - val_loss: 10500615168.0000 - val_accuracy: 0.0000e+00 - 520ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "100/100 - 0s - loss: 16131148800.0000 - accuracy: 0.0000e+00 - val_loss: 10723381248.0000 - val_accuracy: 0.0000e+00 - 492ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "100/100 - 1s - loss: 16259148800.0000 - accuracy: 0.0000e+00 - val_loss: 10578114560.0000 - val_accuracy: 0.0000e+00 - 533ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "100/100 - 0s - loss: 16197704704.0000 - accuracy: 0.0000e+00 - val_loss: 10768620544.0000 - val_accuracy: 0.0000e+00 - 478ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "100/100 - 1s - loss: 16290513920.0000 - accuracy: 0.0000e+00 - val_loss: 10615745536.0000 - val_accuracy: 0.0000e+00 - 535ms/epoch - 5ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1cea32b0be0>"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train the network\n",
        "\n",
        "NN_model.fit(x_train_sd, y_train, epochs=100, verbose = 2, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76fad961",
      "metadata": {
        "id": "76fad961"
      },
      "source": [
        "- the accuracy is not really a regression metric; the one used n regressiuin is R- squared . that is why it is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75daa160",
      "metadata": {
        "id": "75daa160"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6f572457",
      "metadata": {
        "id": "6f572457"
      },
      "source": [
        "## Deep Learning Model Building - Classification Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c648f4dd",
      "metadata": {
        "id": "c648f4dd"
      },
      "outputs": [],
      "source": [
        "## Import required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c16b551",
      "metadata": {
        "id": "1c16b551",
        "outputId": "78873cc9-f7a4-4e9a-c987-7c3e54e40553"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Churn</th>\n",
              "      <th>AccountWeeks</th>\n",
              "      <th>ContractRenewal</th>\n",
              "      <th>DataPlan</th>\n",
              "      <th>DataUsage</th>\n",
              "      <th>CustServCalls</th>\n",
              "      <th>DayMins</th>\n",
              "      <th>DayCalls</th>\n",
              "      <th>MonthlyCharge</th>\n",
              "      <th>OverageFee</th>\n",
              "      <th>RoamMins</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.7</td>\n",
              "      <td>1</td>\n",
              "      <td>265.1</td>\n",
              "      <td>110</td>\n",
              "      <td>89.0</td>\n",
              "      <td>9.87</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1</td>\n",
              "      <td>161.6</td>\n",
              "      <td>123</td>\n",
              "      <td>82.0</td>\n",
              "      <td>9.78</td>\n",
              "      <td>13.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>243.4</td>\n",
              "      <td>114</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.06</td>\n",
              "      <td>12.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>299.4</td>\n",
              "      <td>71</td>\n",
              "      <td>57.0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>6.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>166.7</td>\n",
              "      <td>113</td>\n",
              "      <td>41.0</td>\n",
              "      <td>7.42</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Churn  AccountWeeks  ContractRenewal  DataPlan  DataUsage  CustServCalls  \\\n",
              "0      0           128                1         1        2.7              1   \n",
              "1      0           107                1         1        3.7              1   \n",
              "2      0           137                1         0        0.0              0   \n",
              "3      0            84                0         0        0.0              2   \n",
              "4      0            75                0         0        0.0              3   \n",
              "\n",
              "   DayMins  DayCalls  MonthlyCharge  OverageFee  RoamMins  \n",
              "0    265.1       110           89.0        9.87      10.0  \n",
              "1    161.6       123           82.0        9.78      13.7  \n",
              "2    243.4       114           52.0        6.06      12.2  \n",
              "3    299.4        71           57.0        3.10       6.6  \n",
              "4    166.7       113           41.0        7.42      10.1  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the dataset\n",
        "df = pd.read_csv(\"telecom_churn.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33520feb",
      "metadata": {
        "id": "33520feb"
      },
      "source": [
        "- 0 means customer did not churn\n",
        "- 1 means customer churned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6176f6ed",
      "metadata": {
        "id": "6176f6ed",
        "outputId": "f2ea4caf-8a57-4f33-d6a4-af78dc815060"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Churn              0\n",
              "AccountWeeks       0\n",
              "ContractRenewal    0\n",
              "DataPlan           0\n",
              "DataUsage          0\n",
              "CustServCalls      0\n",
              "DayMins            0\n",
              "DayCalls           0\n",
              "MonthlyCharge      0\n",
              "OverageFee         0\n",
              "RoamMins           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90434163",
      "metadata": {
        "id": "90434163"
      },
      "outputs": [],
      "source": [
        "# select target and features\n",
        "X = df.drop(\"Churn\", axis = 1)\n",
        "y = df[\"Churn\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f1d1c04",
      "metadata": {
        "id": "6f1d1c04"
      },
      "outputs": [],
      "source": [
        "#### Split the dataset into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0,\n",
        "                                                   stratify = y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6c4d9b",
      "metadata": {
        "id": "1a6c4d9b"
      },
      "outputs": [],
      "source": [
        "### Normalize\n",
        "scaler = StandardScaler()\n",
        "x_train_sd = scaler.fit_transform(x_train)\n",
        "x_test_sd = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55068c06",
      "metadata": {
        "id": "55068c06",
        "outputId": "ce2fac9e-0198-47d5-b804-f47e06b2b4b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1112    0\n",
              "3112    1\n",
              "2863    0\n",
              "1909    0\n",
              "273     0\n",
              "       ..\n",
              "213     0\n",
              "398     0\n",
              "228     0\n",
              "3078    0\n",
              "1627    0\n",
              "Name: Churn, Length: 2666, dtype: int64"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbdc294",
      "metadata": {
        "id": "2bbdc294",
        "outputId": "f7bafecb-8d4e-419d-bec6-c463780f87e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int64)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# how will the model know the classes in the target?\n",
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c8fea9",
      "metadata": {
        "id": "e5c8fea9",
        "outputId": "79992469-c8eb-47bc-95f1-a1dcedec61e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_class = len(np.unique(y))\n",
        "n_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b02cb91",
      "metadata": {
        "id": "9b02cb91",
        "outputId": "20f39a72-5233-49bd-b3be-8e3b1c3939cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2666,)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d9592f",
      "metadata": {
        "id": "01d9592f"
      },
      "outputs": [],
      "source": [
        "# converting the label to categoric so the network will understand that it is a category\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c224b36",
      "metadata": {
        "id": "2c224b36",
        "outputId": "b5935b95-4fdd-4a5a-f339-e624c836a5df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445ca3e3",
      "metadata": {
        "id": "445ca3e3",
        "outputId": "69ad9b01-3815-4d37-81ea-868537fdae08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2666, 2)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_cat.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c5f16d",
      "metadata": {
        "id": "47c5f16d"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99cc8ff",
      "metadata": {
        "id": "a99cc8ff",
        "outputId": "4f2ac77b-a6b7-4858-833c-d4b876d27f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 128)               1408      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,720\n",
            "Trainable params: 2,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape = (x_train.shape[1], ), activation = \"relu\"))\n",
        "model.add(Dense(10, activation = \"relu\"))\n",
        "model.add(Dense(n_class, activation = \"sigmoid\"))\n",
        "\n",
        "# print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52dd9980",
      "metadata": {
        "id": "52dd9980"
      },
      "outputs": [],
      "source": [
        "# compile the network\n",
        "opt = Adam()\n",
        "model.compile(optimizer = opt, loss = \"binary_crossentropy\" , metrics=\"accuracy\")\n",
        "# binary_crossentropy is used for classification problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "195694af",
      "metadata": {
        "id": "195694af",
        "outputId": "b6c8df55-22ef-4f1b-a3c9-60510759cf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "67/67 - 2s - loss: 0.5035 - accuracy: 0.8372 - val_loss: 0.3711 - val_accuracy: 0.8633 - 2s/epoch - 37ms/step\n",
            "Epoch 2/10\n",
            "67/67 - 0s - loss: 0.3579 - accuracy: 0.8588 - val_loss: 0.3223 - val_accuracy: 0.8783 - 216ms/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "67/67 - 0s - loss: 0.3216 - accuracy: 0.8654 - val_loss: 0.3007 - val_accuracy: 0.8801 - 312ms/epoch - 5ms/step\n",
            "Epoch 4/10\n",
            "67/67 - 0s - loss: 0.2982 - accuracy: 0.8785 - val_loss: 0.2810 - val_accuracy: 0.8876 - 220ms/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "67/67 - 0s - loss: 0.2775 - accuracy: 0.8884 - val_loss: 0.2654 - val_accuracy: 0.8933 - 182ms/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "67/67 - 0s - loss: 0.2605 - accuracy: 0.8996 - val_loss: 0.2580 - val_accuracy: 0.9007 - 229ms/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "67/67 - 0s - loss: 0.2501 - accuracy: 0.9062 - val_loss: 0.2526 - val_accuracy: 0.9026 - 215ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "67/67 - 0s - loss: 0.2412 - accuracy: 0.9104 - val_loss: 0.2539 - val_accuracy: 0.9064 - 239ms/epoch - 4ms/step\n",
            "Epoch 9/10\n",
            "67/67 - 0s - loss: 0.2370 - accuracy: 0.9184 - val_loss: 0.2495 - val_accuracy: 0.9082 - 221ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "67/67 - 0s - loss: 0.2325 - accuracy: 0.9165 - val_loss: 0.2507 - val_accuracy: 0.9082 - 183ms/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# train the network\n",
        "r = model.fit(x_train_sd, y_train_cat, batch_size = 32, validation_split = 0.2, epochs =10, \n",
        "                   verbose =2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b7f269",
      "metadata": {
        "id": "44b7f269"
      },
      "outputs": [],
      "source": [
        "### Plot the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e978d92b",
      "metadata": {
        "id": "e978d92b",
        "outputId": "dca7212e-c221-4b7b-c781-f91fea213075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38213d92",
      "metadata": {
        "id": "38213d92",
        "outputId": "99f3904e-cd27-4880-bf4d-517ea42a3429"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc= r.history[\"accuracy\"]\n",
        "val_acc = r.history[\"val_accuracy\"] \n",
        "epochs =  range(1, len(acc) + 1)\n",
        "plt.figure(figsize = (8, 5))\n",
        "plt.plot(epochs, acc, label = \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, label = \"Validation Accuracy\")\n",
        "plt.legend (loc= \"best\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aced5308",
      "metadata": {
        "id": "aced5308"
      },
      "source": [
        "- up to the 6th epoch, the validation accuracy was better The model began to overfit after the 9th epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc0c12a",
      "metadata": {
        "id": "5cc0c12a",
        "outputId": "efe119c8-cecf-4acc-a75d-772b9b55a054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[560,  10],\n",
              "       [ 42,  55]], dtype=int64)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### confusion matrix - optional\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "y_pred = model.predict(x_test_sd).argmax(axis =1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f96f69",
      "metadata": {
        "id": "16f96f69",
        "outputId": "6e440cc4-7d02-46f0-ef34-f89c4a3f9d96"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, cmap=\"magma\", fmt=\"d\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\"], yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e929f8",
      "metadata": {
        "id": "46e929f8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}